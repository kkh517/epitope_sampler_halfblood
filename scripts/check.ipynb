{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.io.cif import CifParser\n",
    "\n",
    "def get_xyz_from_cif(cif_file):\n",
    "    parser = CifParser(cif_file)\n",
    "    structure = parser.get_structures()[0]\n",
    "    xyz_coords = []\n",
    "    for site in structure:\n",
    "        xyz_coords.append(site.coords)\n",
    "    return xyz_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemmi\n",
    "\n",
    "def cif_to_pdb(cif_file, pdb_file):\n",
    "    # Read CIF file\n",
    "    doc = gemmi.cif.read_file(cif_file)\n",
    "    block = doc.sole_block()\n",
    "    \n",
    "    # Create a new model\n",
    "    structure = gemmi.make_structure_from_block(block)\n",
    "    \n",
    "    # Write to PDB file\n",
    "    structure.write_pdb(pdb_file)\n",
    "\n",
    "# Example usage\n",
    "cif_to_pdb(\"/home/yubeen/af3_docking_block/benchmark_101/7df1_F_J_C/7df1_f_j_c_ab/7df1_f_j_c_ab_model.cif\", \"output.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('/home/yubeen/af3_docking_block/benchmark_101'):\n",
    "    if ('.' in i) or (len(i.split('_'))<4) : continue\n",
    "    # print(i.lower(), i)\n",
    "    af3_item = i.lower().replace('#','')\n",
    "    input_path = f\"/home/yubeen/af3_docking_block/benchmark_101/{i}/{af3_item}_ab/{af3_item}_ab_model.cif\"\n",
    "    output_path = f'/home/kkh517/alphafold2.3_ab_benchmark/{i}/af3_new_ab_block.pdb'\n",
    "    # print(f\"input_path: {input_path}\")\n",
    "    if not os.path.exists(output_path.replace('af3_new_ab_block.pdb','new_ab_block.pdb')):\n",
    "        output_i = i.replace('Z',i.split('_')[2].lower())\n",
    "        output_path = f'/home/kkh517/alphafold2.3_ab_benchmark/{output_i}/af3_new_ab_block.pdb'\n",
    "    assert os.path.exists(input_path), \"input_path should exists\"\n",
    "    assert os.path.exists(output_path.replace('af3_new_ab_block.pdb','new_ab_block.pdb')), \"output_origin_path should exists\"\n",
    "\n",
    "    cif_to_pdb(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:05<00:00, 19.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir('/home/yubeen/af3_docking_block/benchmark_101')):\n",
    "    if ('.' in i) or (len(i.split('_'))<4) : continue\n",
    "    # print(i.lower(), i)\n",
    "    af3_item = i.lower().replace('#','')\n",
    "    input_path = f\"/home/yubeen/af3_docking_block/benchmark_101/{i}/{af3_item}_ag/{af3_item}_ag_model.cif\"\n",
    "    output_path = f'/home/kkh517/alphafold2.3_ab_benchmark/{i}/af3_new_ag_block.pdb'\n",
    "    # print(f\"input_path: {input_path}\")\n",
    "    if not os.path.exists(output_path.replace('af3_new_ag_block.pdb','new_ag_block.pdb')):\n",
    "        output_i = i.replace('Z',i.split('_')[2].lower())\n",
    "        output_path = f'/home/kkh517/alphafold2.3_ab_benchmark/{output_i}/af3_new_ag_block.pdb'\n",
    "    assert os.path.exists(input_path), \"input_path should exists\"\n",
    "    assert os.path.exists(output_path.replace('af3_new_ag_block.pdb','new_ag_block.pdb')), \"output_origin_path should exists\"\n",
    "\n",
    "    cif_to_pdb(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB file 'X.pdb' written successfully.\n",
      "PDB file 'x_alinged.pdb' written successfully.\n",
      "PDB file 'Y.pdb' written successfully.\n",
      "RMSD: 0.5251359277710124\n",
      "Rotation Matrix (R):\n",
      " [[ 0.91538032 -0.0328748  -0.4012457 ]\n",
      " [ 0.1825922  -0.85435609  0.48655498]\n",
      " [-0.3588021  -0.51864719 -0.77605808]]\n",
      "Translation Vector (t): [0.43716232 0.60630665 1.52220815]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def kabsch_algorithm(X, Y):\n",
    "    \"\"\"\n",
    "    Kabsch Algorithm을 사용하여 X를 Y에 정렬하기 위한 최적 회전 행렬 R과 변환 벡터 t 계산.\n",
    "    \"\"\"\n",
    "    assert X.shape == Y.shape, \"입력 배열 크기가 같아야 합니다.\"\n",
    "    \n",
    "    # 중심화\n",
    "    X_mean = X.mean(axis=0)\n",
    "    Y_mean = Y.mean(axis=0)\n",
    "    X_centered = X - X_mean\n",
    "    Y_centered = Y - Y_mean\n",
    "    \n",
    "    # 상관 행렬 H 계산\n",
    "    H = np.dot(X_centered.T, Y_centered)\n",
    "    \n",
    "    # SVD 분해\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    \n",
    "    # 회전 행렬 R 계산\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "    \n",
    "    # 반사 방지 (det(R) < 0 인 경우 수정)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "    \n",
    "    # 변환 벡터 t 계산\n",
    "    t = Y_mean - np.dot(R, X_mean)\n",
    "    \n",
    "    return R, t\n",
    "\n",
    "def calculate_rmsd(X, Y):\n",
    "    \"\"\"\n",
    "    두 개의 (L,3) ndarray를 받아 RMSD를 계산.\n",
    "    Kabsch Algorithm을 적용하여 최적 정렬 후 계산.\n",
    "    \"\"\"\n",
    "    assert X.shape == Y.shape, \"두 입력 배열의 크기가 같아야 합니다.\"\n",
    "    \n",
    "    # 최적 회전 및 변환 행렬 계산\n",
    "    R, t = kabsch_algorithm(X, Y)\n",
    "    \n",
    "    # 변환 적용 (올바른 회전 적용 방식)\n",
    "    X_aligned = np.dot(R, X.T).T + t\n",
    "    # write_pdb(X, [X.shape[0]], 'X.pdb')\n",
    "    # write_pdb(X_aligned, [X_aligned.shape[0]], 'x_alinged.pdb')\n",
    "    # write_pdb(Y, [Y.shape[0]], 'Y.pdb')\n",
    "    # RMSD 계산\n",
    "    diff = X_aligned - Y\n",
    "    rmsd = np.sqrt(np.sum(diff**2) / X.shape[0])\n",
    "    \n",
    "    return rmsd, R, t\n",
    "\n",
    "# 예제 사용법\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.random.rand(10, 3)\n",
    "    Y = np.random.rand(10, 3)\n",
    "    \n",
    "    rmsd, R, t = calculate_rmsd(X, Y)\n",
    "    print(\"RMSD:\", rmsd)\n",
    "    print(\"Rotation Matrix (R):\\n\", R)\n",
    "    print(\"Translation Vector (t):\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "\n",
    "to1letter = {\n",
    "    \"UNK\": \"X\",\n",
    "    \"ALA\": \"A\",\n",
    "    \"ARG\": \"R\",\n",
    "    \"ASN\": \"N\",\n",
    "    \"ASP\": \"D\",\n",
    "    \"CYS\": \"C\",\n",
    "    \"GLN\": \"Q\",\n",
    "    \"GLU\": \"E\",\n",
    "    \"GLY\": \"G\",\n",
    "    \"HIS\": \"H\",\n",
    "    \"ILE\": \"I\",\n",
    "    \"LEU\": \"L\",\n",
    "    \"LYS\": \"K\",\n",
    "    \"MET\": \"M\",\n",
    "    \"PHE\": \"F\",\n",
    "    \"PRO\": \"P\",\n",
    "    \"SER\": \"S\",\n",
    "    \"THR\": \"T\",\n",
    "    \"TRP\": \"W\",\n",
    "    \"TYR\": \"Y\",\n",
    "    \"VAL\": \"V\",\n",
    "}\n",
    "\n",
    "num2aa=[\n",
    "    'ALA','ARG','ASN','ASP','CYS',\n",
    "    'GLN','GLU','GLY','HIS','ILE',\n",
    "    'LEU','LYS','MET','PHE','PRO',\n",
    "    'SER','THR','TRP','TYR','VAL',\n",
    "    'UNK','MAS',\n",
    "    ]\n",
    "\n",
    "aa2num= {x:i for i,x in enumerate(num2aa)}\n",
    "\n",
    "# full sc atom representation (Nx14)\n",
    "bb_idx = {\" N  \" : 0, \" CA \" : 1, \" C  \" : 2, \" O  \" : 3}\n",
    "aa2long=[\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",  None,  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"3HB \",  None,  None,  None,  None,  None,  None,  None,  None), # ala\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD \",\" NE \",\" CZ \",\" NH1\",\" NH2\",  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",\"1HD \",\"2HD \",\" HE \",\"1HH1\",\"2HH1\",\"1HH2\",\"2HH2\"), # arg\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" OD1\",\" ND2\",  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HD2\",\"2HD2\",  None,  None,  None,  None,  None,  None,  None), # asn\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" OD1\",\" OD2\",  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",  None,  None,  None,  None,  None,  None,  None,  None,  None), # asp\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" SG \",  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\" HG \",  None,  None,  None,  None,  None,  None,  None,  None), # cys\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD \",\" OE1\",\" NE2\",  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",\"1HE2\",\"2HE2\",  None,  None,  None,  None,  None), # gln\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD \",\" OE1\",\" OE2\",  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",  None,  None,  None,  None,  None,  None,  None), # glu\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",  None,  None,  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\"1HA \",\"2HA \",  None,  None,  None,  None,  None,  None,  None,  None,  None,  None), # gly\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" ND1\",\" CD2\",\" CE1\",\" NE2\",  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\" HD2\",\" HE1\",\" HE2\",  None,  None,  None,  None,  None,  None), # his\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG1\",\" CG2\",\" CD1\",  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\" HB \",\"1HG2\",\"2HG2\",\"3HG2\",\"1HG1\",\"2HG1\",\"1HD1\",\"2HD1\",\"3HD1\",  None,  None), # ile\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD1\",\" CD2\",  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\" HG \",\"1HD1\",\"2HD1\",\"3HD1\",\"1HD2\",\"2HD2\",\"3HD2\",  None,  None), # leu\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD \",\" CE \",\" NZ \",  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",\"1HD \",\"2HD \",\"1HE \",\"2HE \",\"1HZ \",\"2HZ \",\"3HZ \"), # lys\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" SD \",\" CE \",  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",\"1HE \",\"2HE \",\"3HE \",  None,  None,  None,  None), # met\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD1\",\" CD2\",\" CE1\",\" CE2\",\" CZ \",  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\" HD1\",\" HD2\",\" HE1\",\" HE2\",\" HZ \",  None,  None,  None,  None), # phe\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD \",  None,  None,  None,  None,  None,  None,  None,\" HA \",\"1HB \",\"2HB \",\"1HG \",\"2HG \",\"1HD \",\"2HD \",  None,  None,  None,  None,  None,  None), # pro\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" OG \",  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HG \",\" HA \",\"1HB \",\"2HB \",  None,  None,  None,  None,  None,  None,  None,  None), # ser\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" OG1\",\" CG2\",  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HG1\",\" HA \",\" HB \",\"1HG2\",\"2HG2\",\"3HG2\",  None,  None,  None,  None,  None,  None), # thr\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD1\",\" CD2\",\" NE1\",\" CE2\",\" CE3\",\" CZ2\",\" CZ3\",\" CH2\",\" H  \",\" HA \",\"1HB \",\"2HB \",\" HD1\",\" HE1\",\" HZ2\",\" HH2\",\" HZ3\",\" HE3\",  None,  None,  None), # trp\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG \",\" CD1\",\" CD2\",\" CE1\",\" CE2\",\" CZ \",\" OH \",  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\" HD1\",\" HE1\",\" HE2\",\" HD2\",\" HH \",  None,  None,  None,  None), # tyr\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",\" CG1\",\" CG2\",  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\" HB \",\"1HG1\",\"2HG1\",\"3HG1\",\"1HG2\",\"2HG2\",\"3HG2\",  None,  None,  None,  None), # val\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",  None,  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"3HB \",  None,  None,  None,  None,  None,  None,  None,  None), # unk\n",
    "    (\" N  \",\" CA \",\" C  \",\" O  \",\" CB \",  None,  None,  None,  None,  None,  None,  None,  None,  None,\" H  \",\" HA \",\"1HB \",\"2HB \",\"3HB \",  None,  None,  None,  None,  None,  None,  None,  None), # mask\n",
    "    ]\n",
    "\n",
    "class QuaternionBase: #from Galaxy.core.quaternion\n",
    "    def __init__(self):\n",
    "        self.q = []\n",
    "    def __repr__(self):\n",
    "        return self.q\n",
    "    def rotate(self):\n",
    "        if 'R' in dir(self):\n",
    "            return self.R\n",
    "        #\n",
    "        self.R = np.zeros((3,3))\n",
    "        #\n",
    "        self.R[0][0] = self.q[0]**2 + self.q[1]**2 - self.q[2]**2 - self.q[3]**2\n",
    "        self.R[0][1] = 2.0*(self.q[1]*self.q[2] - self.q[0]*self.q[3])\n",
    "        self.R[0][2] = 2.0*(self.q[1]*self.q[3] + self.q[0]*self.q[2])\n",
    "        #\n",
    "        self.R[1][0] = 2.0*(self.q[1]*self.q[2] + self.q[0]*self.q[3])\n",
    "        self.R[1][1] = self.q[0]**2 - self.q[1]**2 + self.q[2]**2 - self.q[3]**2\n",
    "        self.R[1][2] = 2.0*(self.q[2]*self.q[3] - self.q[0]*self.q[1])\n",
    "        #\n",
    "        self.R[2][0] = 2.0*(self.q[1]*self.q[3] - self.q[0]*self.q[2])\n",
    "        self.R[2][1] = 2.0*(self.q[2]*self.q[3] + self.q[0]*self.q[1])\n",
    "        self.R[2][2] = self.q[0]**2 - self.q[1]**2 - self.q[2]**2 + self.q[3]**2\n",
    "        return self.R\n",
    "    \n",
    "class QuaternionQ(QuaternionBase):\n",
    "    def __init__(self, q):\n",
    "        self.q = q\n",
    "\n",
    "\n",
    "def ls_rmsd(_X, _Y): #from Galaxy.utils.subPDB\n",
    "    # Kabsch algorithm & turn into quaternion\n",
    "    \n",
    "    X = copy.copy(_X) #(n, 3)\n",
    "    Y = copy.copy(_Y) #(n, 3)\n",
    "    n = float(len(X))\n",
    "\n",
    "    X_cntr = X.transpose().sum(1)/n # (3,)\n",
    "    Y_cntr = Y.transpose().sum(1)/n\n",
    "    X -= X_cntr\n",
    "    Y -= Y_cntr\n",
    "    Xtr = X.transpose() # (3, n)\n",
    "    Ytr = Y.transpose() # (3, n)\n",
    "    X_norm = (Xtr*Xtr).sum() #  \n",
    "    Y_norm = (Ytr*Ytr).sum()\n",
    "    \n",
    "    Rmatrix = np.zeros(9).reshape(3,3)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            Rmatrix[i][j] = Xtr[i].dot(Ytr[j])\n",
    "    S = np.zeros(16).reshape((4,4))\n",
    "    S[0][0] =  Rmatrix[0][0] + Rmatrix[1][1] + Rmatrix[2][2]\n",
    "    S[1][0] =  Rmatrix[1][2] - Rmatrix[2][1]\n",
    "    S[0][1] =  S[1][0]\n",
    "    S[1][1] =  Rmatrix[0][0] - Rmatrix[1][1] - Rmatrix[2][2]\n",
    "    S[2][0] =  Rmatrix[2][0] - Rmatrix[0][2]\n",
    "    S[0][2] =  S[2][0]\n",
    "    S[2][1] =  Rmatrix[0][1] + Rmatrix[1][0]\n",
    "    S[1][2] =  S[2][1]\n",
    "    S[2][2] = -Rmatrix[0][0] + Rmatrix[1][1] - Rmatrix[2][2]\n",
    "    S[3][0] =  Rmatrix[0][1] - Rmatrix[1][0]\n",
    "    S[0][3] =  S[3][0]\n",
    "    S[3][1] =  Rmatrix[0][2] + Rmatrix[2][0]\n",
    "    S[1][3] =  S[3][1]\n",
    "    S[3][2] =  Rmatrix[1][2] + Rmatrix[2][1]\n",
    "    S[2][3] =  S[3][2]\n",
    "    S[3][3] = -Rmatrix[0][0] - Rmatrix[1][1] + Rmatrix[2][2]\n",
    "    #\n",
    "    eigl,eigv = np.linalg.eigh(S) \n",
    "    q = eigv.transpose()[-1] #(4,)\n",
    "    sU = QuaternionQ(q).rotate() #(3,3)\n",
    "    sT = Y_cntr - sU.dot(X_cntr)\n",
    "    #\n",
    "    # breakpoint()\n",
    "\n",
    "    rmsd = np.sqrt(max(0.0, (X_norm + Y_norm - 2.0 * eigl[-1]))/n)\n",
    "    return rmsd, (sT,sU)    \n",
    "\n",
    "class PDB:\n",
    "    def __init__ (self, pdb_fn):\n",
    "        self.pdb_fn = pdb_fn\n",
    "    \n",
    "    def read(self):\n",
    "        sequence = defaultdict(str)\n",
    "        coord_bb = defaultdict(dict)  #chain: {idx: coordinate [3]}\n",
    "        coord_all_atom = defaultdict(dict) #chain: {idx: coordinate [14, 3]}\n",
    "        idx_atm = defaultdict(lambda: defaultdict(list))\n",
    "        coord_bb = defaultdict(defaultdict)\n",
    "        idx_total = defaultdict(set)\n",
    "        with open(self.pdb_fn) as f_pdb:\n",
    "            lines = f_pdb.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('ATOM'):\n",
    "                    chain = line[21]\n",
    "                    #xyz = np.full((14, 3), np.nan, dtype=np.float32)\n",
    "                    resNo, atom, aa = int(line[22:26]), line[12:16], line[17:20]\n",
    "                    idx_total[chain].add(resNo)\n",
    "                    if resNo not in coord_all_atom[chain]:\n",
    "                        coord_all_atom[chain][resNo] = np.full((14, 3), np.nan, dtype=np.float32)\n",
    "                    for i_atm, tgtatm in enumerate(aa2long[aa2num[aa]][:14]):\n",
    "                        if tgtatm == atom:\n",
    "                            coord_all_atom[chain][resNo][i_atm, :] = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "                    #coord_all_atom[chain][resNo] = xyz\n",
    "                    # for i in [' CA ', ' N  ', ' C  ', ' O  ']:\n",
    "                    #     if atom == i:\n",
    "                    #         idx_atm[chain][i].append(resNo)\n",
    "                    # if atom == ' CA ':\n",
    "                    #     sequence[chain] += aa\n",
    "                    # if atom == ' CA ' or atom == ' N  ' or atom == ' C  ' or atom == ' O  ':\n",
    "                    #     if resNo not in coord_bb[chain]:\n",
    "                    #         coord_bb[chain][resNo] = np.full((4, 3), np.nan, dtype = np.float32)\n",
    "                    #     coord_bb[chain][resNo][bb_idx[atom], : ] = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "                    for i in [' CA ']:\n",
    "                        if atom == i:\n",
    "                            idx_atm[chain][i].append(resNo)\n",
    "                    if atom == ' CA ':\n",
    "                        sequence[chain] += aa\n",
    "                    if atom == ' CA ' :\n",
    "                        if resNo not in coord_bb[chain]:\n",
    "                            coord_bb[chain][resNo] = np.full((4, 3), np.nan, dtype = np.float32)\n",
    "                        coord_bb[chain][resNo][bb_idx[atom], : ] = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "                        \n",
    "        return sequence, idx_total, idx_atm, coord_bb, coord_all_atom       \n",
    "# [L, 14, 3]                \n",
    "def get_interface_idx(coord, idx, receptor_chain, ligand_chain, device='cpu', iface_cutoff=10.0):\n",
    "    chain_order = []\n",
    "    receptor_length = 0\n",
    "    ligand_length = 0\n",
    "    for i in receptor_chain:\n",
    "        chain_order.append(i)\n",
    "        receptor_length += len(idx[i])\n",
    "    for i in ligand_chain:\n",
    "        chain_order.append(i)\n",
    "        ligand_length += len(idx[i])\n",
    "    \n",
    "    xyz_tot = []\n",
    "    idx_match = defaultdict(dict)\n",
    "    count = 0\n",
    "    for i in chain_order:\n",
    "        xyz_chain = np.full((len(idx[i]), 14, 3), np.nan, dtype=np.float32)\n",
    "        for j, k in enumerate(idx[i]):\n",
    "            xyz_chain[j, :, :] = coord[i][k]\n",
    "        xyz_chain = torch.from_numpy(xyz_chain)\n",
    "        xyz_tot.append(xyz_chain)\n",
    "        idx_match[i] = dict(zip(list(range(count, count+len(idx[i]))), idx[i]))\n",
    "        count += len(idx[i])\n",
    "    xyz_tot = torch.cat(xyz_tot, dim = 0)\n",
    "    xyz_tot = xyz_tot.to(device=device)    #[total_len, 14, 3]\n",
    "    \n",
    "    dist = xyz_tot[:, None, :, None, :] - xyz_tot[None, :, None, :, :]\n",
    "    dist = (dist**(2)).sum(dim = -1)\n",
    "    dist = (dist)**(0.5) #[L, L, 14, 14]\n",
    "    dist = dist.view(*dist.shape[:2], -1)\n",
    "    dist = torch.nan_to_num(dist, nan=100.0)\n",
    "    dist = torch.min(dist, dim = -1)[0]\n",
    "    dist_dict = defaultdict(dict)\n",
    "#    for i, j in enumerate(dist):\n",
    "#        print(i, j)\n",
    "#        for k, v in idx_match.items():  #A:{0:447, 1:448..}\n",
    "#            print(k, v)\n",
    "#            if i in v.keys():\n",
    "#                dist_dict[k] = j[v[i]]\n",
    "#                break\n",
    "    mask = torch.le(dist, iface_cutoff) #[L, L]\n",
    "    mask[:receptor_length, :receptor_length] = False #False for intra region\n",
    "    mask[receptor_length:, receptor_length:] = False\n",
    "    \n",
    "    interface_lists = torch.unique(torch.where(mask==True)[0])\n",
    "    interface_pair = torch.where(mask==True)\n",
    "    \n",
    "    interface_final = defaultdict(set)\n",
    "    interface_pair_list = set()\n",
    "    for i in interface_lists:\n",
    "        i = i.item()\n",
    "        for k, v in idx_match.items(): #k:chain v:{idx1:resno1, idx2:resno2,...}\n",
    "            if i in v.keys():\n",
    "                interface_final[k].add(v[i])\n",
    "                \n",
    "    for i, j in zip(interface_pair[0], interface_pair[1]):\n",
    "        i = i.item()\n",
    "        j = j.item()\n",
    "        if i < j:\n",
    "            continue\n",
    "        chain_i, chain_j = None, None\n",
    "        idx_i, idx_j = None, None\n",
    "        for k, v in idx_match.items():\n",
    "            if i in v:\n",
    "                chain_i = k\n",
    "                idx_i = v[i]\n",
    "            if j in v:\n",
    "                chain_j = k\n",
    "                idx_j = v[j]\n",
    "        interface_pair_list.add((chain_i, idx_i, chain_j, idx_j))                \n",
    "    \n",
    "    return interface_final, interface_pair_list\n",
    "\n",
    "def calc_rmsd(ref, model, R, t):\n",
    "    assert len(ref) == len(model)\n",
    "    length = len(ref)\n",
    "    # ref = np.array(ref).transpose() #(3, n)\n",
    "    # model = np.array(model).transpose() #(3, n)\n",
    "    # t = t.reshape(3, 1)\n",
    "    # aligned_model = np.einsum('ij, jk -> ik', R, model) + t\n",
    "    # aligned_model = np.dot(R, model.T).T + t\n",
    "    aligned_model = np.dot(R, model.T).T + t\n",
    "    # print(f\"aligned_model shape{aligned_model.shape}\")\n",
    "    # write_pdb(aligned_model, [119, 107], 'aligned_model.pdb')\n",
    "    # write_pdb(ref,[119,107],'ref.pdb')\n",
    "\n",
    "    rmsd = np.sqrt(((aligned_model - ref)**2).sum(0).sum()/length)\n",
    "    return rmsd\n",
    "\n",
    "def get_capri(model_pdb, ref_pdb, receptor_chain, ligand_chain):\n",
    "    \n",
    "    model_seq, model_idx_tot, model_idx_atm, model_coord_bb, model_coord_all = PDB(model_pdb).read()\n",
    "    ref_seq, ref_idx_tot, ref_idx_atm, ref_coord_bb, ref_coord_all = PDB(ref_pdb).read()\n",
    "    \n",
    "    # should only consider overlapped residues (reference does not have to be complete)\n",
    "    idx_overlap = defaultdict(dict)\n",
    "    for ch in model_idx_atm.keys():\n",
    "        for atm in model_idx_atm[ch].keys():\n",
    "            overlap = list(set(model_idx_atm[ch][atm]) & set(ref_idx_atm[ch][atm]))\n",
    "            idx_overlap[ch][atm] = overlap\n",
    "    #print(idx_overlap)\n",
    "    model_rec_bb, ref_rec_bb = [], []\n",
    "    model_lig_bb, ref_lig_bb = [], []\n",
    "    \n",
    "    # print('model_coord_bb', model_coord_bb.keys())\n",
    "    # print('ref_coord_bb', ref_coord_bb.keys())\n",
    "    # print('receptor_chain', receptor_chain)\n",
    "    # print('ligand_chain', ligand_chain)\n",
    "    for i in receptor_chain:\n",
    "        for atm in idx_overlap[i].keys():\n",
    "            for idx in idx_overlap[i][atm]:\n",
    "                model_rec_bb.append(model_coord_bb[i][idx][bb_idx[atm]])\n",
    "                ref_rec_bb.append(ref_coord_bb[i][idx][bb_idx[atm]])\n",
    "    \n",
    "    for i in ligand_chain:\n",
    "        for atm in idx_overlap[i].keys():\n",
    "            for idx in idx_overlap[i][atm]:\n",
    "                model_lig_bb.append(model_coord_bb[i][idx][bb_idx[atm]])\n",
    "                ref_lig_bb.append(ref_coord_bb[i][idx][bb_idx[atm]])\n",
    "    \n",
    "    # print('model_rec_bb', model_rec_bb)\n",
    "    # print('ref_rec_bb', ref_rec_bb)\n",
    "    model_rec_bb = np.array(model_rec_bb)\n",
    "    ref_rec_bb = np.array(ref_rec_bb)\n",
    "    model_lig_bb = np.array(model_lig_bb)\n",
    "    ref_lig_bb = np.array(ref_lig_bb)\n",
    "    \n",
    "    model_rec_bb = model_rec_bb.reshape(-1, 3)\n",
    "    ref_rec_bb = ref_rec_bb.reshape(-1, 3)\n",
    "    model_lig_bb = model_lig_bb.reshape(-1, 3)\n",
    "    ref_lig_bb = ref_lig_bb.reshape(-1, 3)\n",
    "    \n",
    "    #print('model_shape', model_rec_bb.shape)\n",
    "    #print('ref_shape', ref_rec_bb.shape)\n",
    "    assert model_rec_bb.shape == ref_rec_bb.shape\n",
    "    assert model_lig_bb.shape == ref_lig_bb.shape\n",
    "    \n",
    "    #1. Calculate l-rmsd\n",
    "    # Get receptor aligned R, T matrix\n",
    "    model_bb = np.concatenate((model_rec_bb, model_lig_bb))\n",
    "    ref_bb = np.concatenate((ref_rec_bb, ref_lig_bb))\n",
    "\n",
    "    total_rmsd, (t_rec, R_rec) = ls_rmsd(model_bb, ref_bb)\n",
    "    # total_rmsd, R_tot, t_tot = calculate_rmsd(model_bb, ref_bb)\n",
    "    # print(model_bb.shape)\n",
    "    print(f\"total rmsd {total_rmsd}\")\n",
    "    receptor_rmsd, (t_rec, R_rec) = ls_rmsd(model_rec_bb, ref_rec_bb)\n",
    "    # receptor_rmsd, R_rec, t_rec = calculate_rmsd(model_rec_bb, ref_rec_bb)\n",
    "    print(f\"receptor rmsd {receptor_rmsd}\")\n",
    "    l_rmsd = calc_rmsd(ref_lig_bb, model_lig_bb, R_rec, t_rec)\n",
    "    \n",
    "    \n",
    "    #2. Calculate i-rmsd\n",
    "    # Get interface region of refernce \n",
    "    model_interface_bb = []\n",
    "    ref_interface_bb = []\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('device', device)\n",
    "    ref_idx_interface, ref_pair_interface = get_interface_idx(ref_coord_all, ref_idx_tot, receptor_chain, ligand_chain, \\\n",
    "            iface_cutoff = 10.0, device = device)\n",
    "    \n",
    "    count_ori = defaultdict(int)\n",
    "    for k, v in ref_idx_interface.items(): #k: chain #v: interface residue index\n",
    "        sort_idx = sorted(v)\n",
    "        for atm in idx_overlap[k].keys(): #if both exists in receptor and ligan\n",
    "            for idx in sort_idx:\n",
    "                if idx in idx_overlap[k][atm]:\n",
    "                    model_interface_bb.append(model_coord_bb[k][idx][bb_idx[atm]])\n",
    "                    ref_interface_bb.append(ref_coord_bb[k][idx][bb_idx[atm]])\n",
    "\n",
    "    model_interface_bb = np.array(model_interface_bb)\n",
    "    ref_interface_bb = np.array(ref_interface_bb)\n",
    "    \n",
    "    model_interface_bb = model_interface_bb.reshape(-1, 3)\n",
    "    ref_interface_bb = ref_interface_bb.reshape(-1, 3)\n",
    "    \n",
    "    # print('model_interface_bb', model_interface_bb)\n",
    "    # print('ref_interface_bb', ref_interface_bb)\n",
    "    i_rmsd, (t_inf, R_inf) = ls_rmsd(model_interface_bb, ref_interface_bb)\n",
    "    # i_rmsd, R_inf, t_inf = calculate_rmsd(model_interface_bb, ref_interface_bb)\n",
    "    \n",
    "    model_coord_all_overlap = defaultdict(dict)\n",
    "    # print(f\"model_coord_all\\n{model_coord_all}\")\n",
    "    print(model_coord_all.keys())\n",
    "    # try:\n",
    "    for ch, idxs in ref_coord_all.items():\n",
    "        for idx in idxs:\n",
    "            model_coord_all_overlap[ch][idx] = model_coord_all[ch][idx]\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error: {e}\")\n",
    "    #     print(f\"model_coord_all: {model_coord_all.keys()}\")\n",
    "    #     print(f\"ref_coord_all: {ref_coord_all.keys()}\")\n",
    "        # continue\n",
    "\n",
    "    #3. Calculate fNAT\n",
    "    ref_idx_interface, ref_pair_interface = get_interface_idx(ref_coord_all, ref_idx_tot, receptor_chain, ligand_chain, iface_cutoff = 5.0)\n",
    "    model_idx_interface, model_pair_interface = get_interface_idx(model_coord_all_overlap, ref_idx_tot, receptor_chain, ligand_chain, iface_cutoff = 5.0)\n",
    "    \n",
    "    pair_both = set(ref_pair_interface) & set(model_pair_interface)\n",
    "    f_nat = float(len(pair_both))/len(set(ref_pair_interface))\n",
    "    \n",
    "    return l_rmsd, i_rmsd, f_nat\n",
    "\n",
    "def eval_fnat(fnat):\n",
    "    if fnat >= 0.5:\n",
    "        return 'high'\n",
    "    elif fnat >= 0.3:\n",
    "        return 'medium'\n",
    "    elif fnat >= 0.1:\n",
    "        return 'acceptable'\n",
    "    elif fnat < 0.1:\n",
    "        return 'incorrect'\n",
    "\n",
    "def eval_lrmsd(lrmsd):\n",
    "    if lrmsd <= 1.0:\n",
    "        return 'high'\n",
    "    elif lrmsd <= 5.0:\n",
    "        return 'medium'\n",
    "    elif lrmsd <= 10.0:\n",
    "        return 'acceptable'\n",
    "    elif lrmsd > 10.0:\n",
    "        return 'incorrect'\n",
    "\n",
    "def eval_irmsd(irmsd):\n",
    "    if irmsd <= 1.0:\n",
    "        return 'high'\n",
    "    elif irmsd <= 2.0:\n",
    "        return 'medium'\n",
    "    elif irmsd <= 4.0:\n",
    "        return 'acceptable'\n",
    "    elif irmsd > 4.0:\n",
    "        return 'incorrect'\n",
    "\n",
    "#lst = ['high', 'medium', 'acceptable', 'incorrect']\n",
    "lst_dict = {'high':3, 'medium':2, 'acceptable':1, 'incorrect':0}\n",
    "lst_dict_reverse = {3: 'high', 2:'medium', 1:'acceptable', 0:'incorrect'}\n",
    "\n",
    "def calc_capri_criteria(lrmsd, irmsd, fnat):\n",
    "    lrmsd_num = lst_dict[eval_lrmsd(lrmsd)]\n",
    "    irmsd_num = lst_dict[eval_irmsd(irmsd)]\n",
    "    fnat_num = lst_dict[eval_fnat(fnat)]\n",
    "    result = min(fnat_num, max(lrmsd_num, irmsd_num))\n",
    "    \n",
    "    return lst_dict_reverse[result]\n",
    "\n",
    "\n",
    "def calc_dockq(lrmsd, irmsd, fnat):\n",
    "    lrmsd, irmsd = 1/(1+(lrmsd/8.5)**2), 1/(1+(irmsd/1.5)**2)\n",
    "    dockq = (lrmsd + irmsd + fnat)/3\n",
    "    return dockq\n",
    "\n",
    "\n",
    "def change_chain(pdb, name):\n",
    "   # change the chain name and chain numbering to chothia\n",
    "    chains = []\n",
    "    _, hchain, lchain, agchain = name.split('_')[:4]\n",
    "    \n",
    "    #for AF-based\n",
    "    #chain_dict = AF_get_chain_dict(name)\n",
    "    #print(chain_dict)\n",
    "    \n",
    "    # for RF\n",
    "    for i in [hchain, lchain, agchain]:\n",
    "        if i != '#':\n",
    "            for j in i:\n",
    "                chains.append(j)\n",
    "                \n",
    "    # chain_alphabet = list(string.ascii_uppercase)\n",
    "    chain_alphabet=['H','L','T']\n",
    "    chain_dict = dict(zip(chain_alphabet, chains))\n",
    "    \n",
    "    newlines = []\n",
    "    pdblines = open(pdb).readlines()\n",
    "    antigen_not_exist = True\n",
    "    for line in pdblines:\n",
    "        if line.startswith('ATOM'):\n",
    "            chain = line[21]\n",
    "            new_chain = chain_dict[chain]\n",
    "            if new_chain in agchain:\n",
    "                antigen_not_exist = False\n",
    "            if line[21] == 'L':\n",
    "                if line[21] == 'L':\n",
    "                    line = line[:23] + f\"{int(line[23:26]) - 115:3d}\" + line[26:]\n",
    "            newline = f'{line[:21]}{new_chain}{line[22:]}'\n",
    "            newlines.append(newline)\n",
    "        else:\n",
    "            newlines.append(line)\n",
    "    #if antigen_not_exist == True:\n",
    "    #    print(pdb)\n",
    "    # os.makedirs(f'{Path(pdb).parent}/get_capri', exist_ok=True)\n",
    "    # new_filename = f'{Path(pdb).parent}/get_capri/{Path(pdb).stem}_rechain.pdb'\n",
    "    new_filename=f'{Path(pdb).stem}_rechain.pdb'\n",
    "    f_out = open(new_filename, 'w')\n",
    "    f_out.writelines(newlines)\n",
    "    f_out.write('TER\\n')\n",
    "    f_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th_epi_7sbd_H_L_C_3_HLT_best_rechain.pdb\n"
     ]
    }
   ],
   "source": [
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_wt.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_goodMPNN_350.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_badMPNN_350.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_wt_mAb.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_goodMPNN_mAb.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_badMPNN_mAb.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_bd_c.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_gd_c.pdb\"\n",
    "# pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/scripts/999th_epi_1s78_D_C_A_gt_c.pdb\"\n",
    "pdb = \"/home/kkh517/Github/RFantibody/scripts/examples/rf2/example_outputs/15th_epi_7sbd_H_L_C_3_HLT_best.pdb\"\n",
    "change_chain(pdb, '7sbd_H_L_C')\n",
    "# model_pdb = f'{Path(pdb).parent}/get_capri/{Path(pdb).stem}_rechain.pdb'\n",
    "model_pdb = f'{Path(pdb).stem}_rechain.pdb'\n",
    "# model_pdb = f\"7sbd_H_L_C_RFantibody_output.pdb\"\n",
    "print(model_pdb)\n",
    "# ref_pdb = \"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/antibody_meeting_inputs/1s78_D_C_A_wt/1s78_D_C_A_renum.pdb\"\n",
    "# ref_pdb =\"/home/kkh517/submit_files/Project/epitope_sampler_halfblood/antibody_meeting_inputs/1s78_D_C_A_wt/1s78_D_C_A_renum.pdb\"\n",
    "ref_pdb = \"/home/kkh517/benchmark_set_after210930/7sbd_H_L_C/new.pdb\"\n",
    "# print(f\"TMscore -c -ter 0 {model_pdb} {ref_pdb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rmsd 12.78239818633521\n",
      "receptor rmsd 1.734770995509093\n",
      "device cpu\n",
      "dict_keys(['H', 'L', 'C'])\n",
      "37.34305432220897 14.237077566103983 0.03508771929824561 0.03177491608353966 incorrect\n"
     ]
    }
   ],
   "source": [
    "ab_chain = 'HL' ; ag_chain = 'C'\n",
    "l_rmsd, i_rmsd, f_nat = get_capri(model_pdb, ref_pdb, receptor_chain=ag_chain, ligand_chain=ab_chain)\n",
    "# l_rmsd, i_rmsd, f_nat = get_capri(model_pdb, ref_pdb, receptor_chain='C', ligand_chain='DC')\n",
    "capri_criteria = calc_capri_criteria(l_rmsd, i_rmsd, f_nat)\n",
    "dockq = calc_dockq(l_rmsd, i_rmsd, f_nat)\n",
    "print(l_rmsd, i_rmsd, f_nat, dockq, capri_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def write_pdb(xyz_tensor, L_s, output_file=\"output.pdb\"):\n",
    "    \"\"\"\n",
    "    Write a PDB file from an XYZ tensor and chain length list.\n",
    "    \n",
    "    Parameters:\n",
    "    xyz_tensor (np.ndarray): Tensor of shape (N, 3) containing atomic coordinates.\n",
    "    L_s (list): List of chain lengths.\n",
    "    output_file (str): Output PDB file name.\n",
    "    \"\"\"\n",
    "    atom_format = \"ATOM  {:5d}  CA  ALA {:1s}{:4d}    {:8.3f}{:8.3f}{:8.3f}  1.00  0.00           C\"\n",
    "    ter_format = \"TER\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        atom_index = 1\n",
    "        res_index = 1\n",
    "        xyz_index = 0\n",
    "        chain_id = 'A'\n",
    "        \n",
    "        for chain_length in L_s:\n",
    "            for _ in range(chain_length):\n",
    "                if xyz_index >= len(xyz_tensor):\n",
    "                    raise ValueError(\"xyz_tensor length is smaller than the sum of L_s.\")\n",
    "                f.write(atom_format.format(atom_index, chain_id, res_index, *xyz_tensor[xyz_index]) + \"\\n\")\n",
    "                atom_index += 1\n",
    "                res_index += 1\n",
    "                xyz_index += 1\n",
    "            \n",
    "            # Write TER after each chain\n",
    "            f.write(ter_format + \"\\n\")\n",
    "            \n",
    "            # Update chain_id to the next alphabet\n",
    "            chain_id = chr(ord(chain_id) + 1)\n",
    "            res_index = 1  # Reset residue index for the new chain\n",
    "\n",
    "    print(f\"PDB file '{output_file}' written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points with '[Errno 2] No such file or directory:':\n",
      "['7uij_H_L_CD', '7vgr_D_C_AB', '7y9t_D_#_AB', '7yix_D_Z_AB', '8b7h_H_L_AB', '8eln_L_#_IJ', '8et0_D_#_AB', '8j80_E_C_AB', '8ozb_C_#_EF', '8pnu_J_#_GHI', '8pnu_J_#_GHI', '8t03_C_D_AB', '8t05_C_D_AB', '8tqi_H_L_AB', '8u3s_B_#_AC', '8ulf_H_L_AB', '9g7k_C_#_AB', '9ima_C_D_AB']\n",
      "17\n",
      "\n",
      "Sorted data points by size:\n",
      "Item: 8c3l_D_#_C, Size:  183\n",
      "Item: 8qf4_E_#_A, Size:  203\n",
      "Item: 8pih_C_#_A, Size:  251\n",
      "Item: 8c5h_N_#_S, Size:  257\n",
      "Item: 8ozb_C_#_EF, Size:  269\n",
      "Item: 8k33_B_#_A, Size:  270\n",
      "Item: 8pij_B_#_A, Size:  289\n",
      "Item: 9fzc_D_#_B, Size:  296\n",
      "Item: 8d9y_B_A_I, Size:  304\n",
      "Item: 7w71_I_M_B, Size:  316\n",
      "Item: 8f5i_X_Y_A, Size:  332\n",
      "Item: 7wki_B_#_A, Size:  334\n",
      "Item: 7yru_H_L_A, Size:  337\n",
      "Item: 8djg_C_D_E, Size:  338\n",
      "Item: 8av2_C_#_A, Size:  339\n",
      "Item: 8jel_C_D_J, Size:  341\n",
      "Item: 8rz0_F_Z_E, Size:  354\n",
      "Item: 7sbd_H_L_C, Size:  358\n",
      "Item: 8gkl_H_L_E, Size:  361\n",
      "Item: 8dcn_D_E_F, Size:  362\n",
      "Item: 8f6o_A_B_C, Size:  363\n",
      "Item: 8db4_A_B_E, Size:  365\n",
      "Item: 7ox1_A_B_G, Size:  366\n",
      "Item: 7yz9_B_#_A, Size:  382\n",
      "Item: 8q3j_C_B_A, Size:  384\n",
      "Item: 8urf_H_L_A, Size:  384\n",
      "Item: 7upm_B_#_A, Size:  386\n",
      "Item: 8ath_E_F_B, Size:  395\n",
      "Item: 7q6c_H_L_A, Size:  396\n",
      "Item: 9g7k_C_#_AB, Size:  402\n",
      "Item: 7unz_A_#_D, Size:  405\n",
      "Item: 7tzh_C_Z_D, Size:  418\n",
      "Item: 8bw0_H_L_C, Size:  420\n",
      "Item: 8aci_H_L_A, Size:  426\n",
      "Item: 8r9y_B_C_A, Size:  443\n",
      "Item: 8jnk_I_M_A, Size:  459\n",
      "Item: 8e0e_B_#_A, Size:  471\n",
      "Item: 7pa5_B_#_A, Size:  490\n",
      "Item: 8hbv_B_#_A, Size:  494\n",
      "Item: 8vvl_H_L_A, Size:  494\n",
      "Item: 8f5n_H_L_A, Size:  509\n",
      "Item: 8b7h_H_L_AB, Size:  514\n",
      "Item: 8h3x_A_#_C, Size:  525\n",
      "Item: 8slb_H_L_A, Size:  525\n",
      "Item: 8u3s_B_#_AC, Size:  539\n",
      "Item: 8c7m_C_D_B, Size:  541\n",
      "Item: 7wn1_C_#_A, Size:  544\n",
      "Item: 7qbf_B_#_A, Size:  546\n",
      "Item: 8dn7_D_H_E, Size:  548\n",
      "Item: 7uij_H_L_CD, Size:  551\n",
      "Item: 8cz5_H_L_A, Size:  562\n",
      "Item: 8ulf_H_L_AB, Size:  569\n",
      "Item: 8d0a_H_L_A, Size:  573\n",
      "Item: 7quh_H_L_A, Size:  576\n",
      "Item: 8pe1_D_#_B, Size:  582\n",
      "Item: 7zau_B_#_A, Size:  630\n",
      "Item: 8dke_A_B_P, Size:  634\n",
      "Item: 7tuf_A_B_C, Size:  642\n",
      "Item: 7tpg_H_L_B, Size:  643\n",
      "Item: 8bb7_C_#_A, Size:  653\n",
      "Item: 8hpk_H_L_A, Size:  653\n",
      "Item: 8sic_A_B_E, Size:  662\n",
      "Item: 7zxk_J_I_AB, Size:  663\n",
      "Item: 8pnl_B_#_A, Size:  664\n",
      "Item: 8t05_C_D_AB, Size:  667\n",
      "Item: 8t03_C_D_AB, Size:  669\n",
      "Item: 8kae_N_#_R, Size:  677\n",
      "Item: 8pnu_J_#_GHI, Size:  678\n",
      "Item: 7df1_F_J_C, Size:  682\n",
      "Item: 8hs2_B_C_R, Size:  688\n",
      "Item: 7ura_H_L_A, Size:  690\n",
      "Item: 7qbg_E_#_CB, Size:  691\n",
      "Item: 8jtw_B_#_A, Size:  696\n",
      "Item: 8tg9_E_F_B, Size:  699\n",
      "Item: 7qha_C_#_BA, Size:  702\n",
      "Item: 8vyl_E_#_ACBD, Size:  718\n",
      "Item: 7vgr_D_C_AB, Size:  723\n",
      "Item: 8eln_L_#_IJ, Size:  728\n",
      "Item: 8vzo_B_D_A, Size:  787\n",
      "Item: 7sla_B_#_A, Size:  799\n",
      "Item: 8smm_H_L_A, Size:  831\n",
      "Item: 8pyr_H_#_EFG, Size:  866\n",
      "Item: 8djm_H_L_BA, Size:  892\n",
      "Item: 8oxv_B_C_A, Size:  925\n",
      "Item: 9ima_C_D_AB, Size:  929\n",
      "Item: 8pg0_H_L_A, Size:  938\n",
      "Item: 7zlh_H_L_A, Size:  939\n",
      "Item: 8j80_E_C_AB, Size:  1009\n",
      "Item: 8scx_H_L_ABC, Size:  1039\n",
      "Item: 8cd0_C_#_A, Size:  1044\n",
      "Item: 7yai_C_#_A, Size:  1075\n",
      "Item: 7u8g_D_E_A, Size:  1095\n",
      "Item: 8tqi_H_L_AB, Size:  1135\n",
      "Item: 8ghr_D_#_B, Size:  1139\n",
      "Item: 8sgj_H_L_A, Size:  1212\n",
      "Item: 8dp0_B_#_A, Size:  1238\n",
      "Item: 7yix_D_Z_AB, Size:  1264\n",
      "Item: 8et0_D_#_AB, Size:  1314\n",
      "Item: 7y9t_D_#_AB, Size:  1367\n",
      "Item: 8tco_F_G_ABC, Size:  1712\n",
      "Item: 7z12_B_C_A, Size:  2270\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Identify data points with \"[Errno 2] No such file or directory:\"\n",
    "error_data_points = []\n",
    "with open('/home/kkh517/submit_files/Project/epitope_sampler_halfblood/test.log', 'r') as file:\n",
    "    for line in file:\n",
    "        if \"[Errno 2] No such file or directory:\" in line:\n",
    "            split_line = line.split('/')\n",
    "            error_data_points.append(split_line[-4])\n",
    "\n",
    "# Task 2: Sort data points by size\n",
    "data_points = []\n",
    "with open('/home/kkh517/submit_files/Project/epitope_sampler_halfblood/test.log', 'r') as file:\n",
    "    for line in file:\n",
    "        if \"#\"*50 in line:\n",
    "            item = next(file).strip()\n",
    "            size = next(file).strip()\n",
    "            data_points.append((item, size))\n",
    "\n",
    "sorted_data_points = sorted(data_points, key=lambda x: int(x[1].split(':')[-1]))\n",
    "\n",
    "# Print the results\n",
    "print(\"Data points with '[Errno 2] No such file or directory:':\")\n",
    "print(error_data_points)\n",
    "print(len(set(error_data_points)))\n",
    "print(\"\\nSorted data points by size:\")\n",
    "gpu02_dict = {}\n",
    "gpu01_dict = {}\n",
    "gpu01_dict2 = {}\n",
    "i = 0\n",
    "length_dict = {}\n",
    "for item, size in sorted_data_points:\n",
    "    size = size.split(':')[-1]\n",
    "    item = item.split(':')[-1].split(\"'\")[-2]\n",
    "    print(f\"Item: {item}, Size: {size}\")\n",
    "    length_dict[item] = int(size)\n",
    "    i+=1\n",
    "    if int(size) > 800:\n",
    "        if i %2 == 0:\n",
    "            gpu01_dict[f\"{str(i)}\"] = [f\"{item}\"]\n",
    "        else:\n",
    "            gpu01_dict2[f'{str(i)}'] = [f'{item}']\n",
    "    else:\n",
    "        gpu02_dict[f\"{str(i)}\"] = [f\"{item}\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "item.split(':')[-1].split(\"'\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7uij_H_L_CD CD\n",
      "7vgr_D_C_AB AB\n",
      "7y9t_D_#_AB AB\n",
      "7yix_D_Z_AB AB\n",
      "8b7h_H_L_AB AB\n",
      "8eln_L_#_IJ IJ\n",
      "8et0_D_#_AB AB\n",
      "8j80_E_C_AB AB\n",
      "8ozb_C_#_EF EF\n",
      "8pnu_J_#_GHI GHI\n",
      "8pnu_J_#_GHI GHI\n",
      "8t03_C_D_AB AB\n",
      "8t05_C_D_AB AB\n",
      "8tqi_H_L_AB AB\n",
      "8u3s_B_#_AC AC\n",
      "8ulf_H_L_AB AB\n",
      "9g7k_C_#_AB AB\n",
      "9ima_C_D_AB AB\n"
     ]
    }
   ],
   "source": [
    "for name in error_data_points:\n",
    "    print(name, name.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu01_dict saved as JSON file: /home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu01_dict.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu01_dict.json'\n",
    "\n",
    "# Save gpu01_dict as a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(gpu01_dict, file)\n",
    "\n",
    "print(f\"gpu01_dict saved as JSON file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu01_dict saved as JSON file: /home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu01_dict2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu01_dict2.json'\n",
    "\n",
    "# Save gpu01_dict as a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(gpu01_dict2, file)\n",
    "\n",
    "print(f\"gpu01_dict saved as JSON file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu02_dict saved as JSON file: /home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu02_dict.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/home/kkh517/submit_files/Project/epitope_sampler_halfblood/gpu02_dict.json'\n",
    "\n",
    "# Save gpu01_dict as a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(gpu02_dict, file)\n",
    "\n",
    "print(f\"gpu02_dict saved as JSON file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpu01_dict),len(gpu01_dict2),len(gpu02_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(gpu01_dict.values()) + list(gpu01_dict2.values()) + list(gpu02_dict.values())\n",
    "vals = set([i for sublist in vals for i in sublist])\n",
    "# vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "already_set = set(os.listdir('/home/kkh517/submit_files/Project/epitope_sampler_halfblood/inference_pdb/halfblood_1.0.1_After210930_ES/'))\n",
    "already_set = set([i for i in already_set if len(i.split('_'))>3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for i in set(already_set):\n",
    "    # print(i, length_dict[i])\n",
    "    if length_dict[i] > length:\n",
    "        length = length_dict[i]\n",
    "        # print(i, length)\n",
    "\n",
    "length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anarci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
