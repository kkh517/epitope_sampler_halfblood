"""This module contains function for parsing
    a3m files(.a3m),
    pdb files(.pdb),
    and template files(.a3m,.hhr )
"""

import re
import string
import gzip
import torch
import numpy as np
import time
from collections import defaultdict, namedtuple
from rfabag.common.chemical import aa2long, aa2num
from rfabag.data.ffindex import read_index, read_data, get_entry_by_name, read_entry_lines

to1letter = {
    "ALA": "A",
    "ARG": "R",
    "ASN": "N",
    "ASP": "D",
    "CYS": "C",
    "GLN": "Q",
    "GLU": "E",
    "GLY": "G",
    "HIS": "H",
    "ILE": "I",
    "LEU": "L",
    "LYS": "K",
    "MET": "M",
    "PHE": "F",
    "PRO": "P",
    "SER": "S",
    "THR": "T",
    "TRP": "W",
    "TYR": "Y",
    "VAL": "V",
}


def parse_a3m(filename, max_seq=8000):

    """Read A3M file and convert letters into integers in the 0..20 range,
      Also keep track of insertions

    Args:
        filename (str): name of a3m file

    Returns:
        msa: information about msa (0-19 for aa, 20 for gap)    [N_seq, L]
        ins: information about insertion                        [N_seq, L]
    """

    msa = []
    ins = []

    table = str.maketrans(dict.fromkeys(string.ascii_lowercase))

    if filename.split(".")[-1] == "gz":
        file_pointer = gzip.open(filename, "rt", encoding="utf-8")
    else:
        file_pointer = open(filename, "r", encoding="utf-8")

    # read file line by line
    for line in file_pointer:

        # skip labels
        if line[0] == ">":
            continue

        # remove right whitespaces
        line = line.rstrip()

        if len(line) == 0:
            continue

        # remove lowercase letters and append to MSA
        msa.append(line.translate(table))

        # sequence length
        length = len(msa[-1])

        # 0 - match or gap; 1 - insertion
        info = np.array([0 if c.isupper() or c == "-" else 1 for c in line])
        insertion = np.zeros((length))

        if np.sum(info) > 0:
            # positions of insertions
            pos = np.where(info == 1)[0]

            # shift by occurrence
            info = pos - np.arange(pos.shape[0])

            # position of insertions in cleaned sequence
            # and their length
            pos, num = np.unique(info, return_counts=True)

            # append to the matrix of insetions
            insertion[pos] = num

        ins.append(insertion)
        if len(msa) == max_seq:
            break

    # convert letters into numbers
    alphabet = np.array(list("ARNDCQEGHILKMFPSTWYV-"), dtype="|S1").view(np.uint8)
    msa = np.array([list(s) for s in msa], dtype="|S1").view(np.uint8)
    for i in range(alphabet.shape[0]):
        msa[msa == alphabet[i]] = i

    # treat all unknown characters as gaps
    msa[msa > 20] = 20

    ins = np.array(ins, dtype=np.uint8)

    return msa, ins


def parse_pdb(filename):

    """Read and extract xyz coords of N, Ca, C atoms from a PDB file

    Args:
        filename (str): name of pdb file

    Returns:
        xyz:  xyz coordinate of pdb file    [L, 14, 3] (14: 4BB + up to 10 SC atoms)
        mask: mask for atom existence       [L, 14]
        np.array(idx_s): residue number     [L]
    """

    lines = open(filename, "r", encoding="utf-8").readlines()
    xyz, mask, idx =  parse_pdb_lines(lines)
    return {'xyz':torch.tensor(xyz),'mask':torch.tensor(mask),'idx': torch.tensor(idx)}


def parse_pdb_lines(lines):

    """Read and extract xyz coords of N, Ca, C atoms from a PDB file

    Args:
        lines (list): list of lines of PDB file

    Returns:
        xyz:  xyz coordinate of pdb file    [L, 14, 3] (14: 4BB + up to 10 SC atoms)
        mask: mask for atom existence       [L, 14]
        np.array(idx_s): residue number     [L]
    """

    # indices of residues observed in the structure
    idx_s = [
        int(l[22:26]) for l in lines if l[:4] == "ATOM" and l[12:16].strip() == "CA"
    ]

    # 4 BB + up to 10 SC atoms
    xyz = np.full((len(idx_s), 14, 3), np.nan, dtype=np.float32)
    for line in lines:
        if line[:4] != "ATOM":
            continue
        resNo, atom, aa = int(line[22:26]), line[12:16], line[17:20]
        idx = idx_s.index(resNo)
        for i_atm, tgtatm in enumerate(aa2long[aa2num[aa]]):
            if tgtatm == atom and i_atm < 14:
                xyz[idx, i_atm, :] = [float(line[30:38]),float(line[38:46]),float(line[46:54])]
                break

    # save atom mask
    mask = np.logical_not(np.isnan(xyz[..., 0]))
    xyz[np.isnan(xyz[..., 0])] = 0.0

    return xyz, mask, np.array(idx_s)


def parse_pdb_antibody(filename, item, antibody=True):

    """Same function as parse_pdb but for antibody"""
    lines = open(filename, "r", encoding="utf-8").readlines()
    xyz, mask, idx = parse_pdb_lines_antibody(lines, item, antibody=antibody)
    #print('pdb xyz', list(pdb['xyz']))
    #print('pdb xyz', list(pdb['xyz']))
    return {
        "xyz": xyz,
        "mask": mask,
        "idx": idx,
    }

def parse_pdb_antibody_old(filename, item):

    """Same function as parse_pdb but for antibody -> add chain_id"""
    lines = open(filename, "r", encoding="utf-8").readlines()
    xyz, mask, idx, chain_id = parse_pdb_lines_antibody_old(lines, item)
    #print('pdb xyz', list(pdb['xyz']))
    #print('pdb xyz', list(pdb['xyz']))
    return {
        "xyz": torch.tensor(xyz),
        "mask": torch.tensor(mask),
        "idx": torch.tensor(idx),
        "chain_id": torch.tensor(chain_id),
    }


def parse_pdb_lines_antibody_old(lines, item):

    """Same function as parse_pdb but for antibody -> add chain_id"""
    chains = []
    for i in item.split("_")[1:]:
        for j in i:
            chains.append(j)

    remove_set = {"#"}
    chains = [i for i in chains if i not in remove_set]

    idx_s = [int(l[22:26]) for l in lines if l[:4] == "ATOM" and l[12:16].strip() == "CA"]
    chain_id = [chains.index(l[21]) for l in lines if l[:4] == "ATOM" and l[12:16].strip() == "CA"]


    xyz = np.full((len(idx_s), 14, 3), np.nan, dtype=np.float32)
    for l in lines:
        if l[:4] != "ATOM":
            continue
        resNo, atom, aa = int(l[22:26]), l[12:16], l[17:20]
        idx = idx_s.index(resNo)
        for i_atm, tgtatm in enumerate(aa2long[aa2num[aa]]):
            if tgtatm == atom and i_atm < 14:
                xyz[idx, i_atm, :] = [float(l[30:38]), float(l[38:46]), float(l[46:54])]
                break
    mask = np.logical_not(np.isnan(xyz[..., 0]))
    #print(mask.shape)
    #for i , m in enumerate(mask):
    #    print(i, m)
    xyz[np.isnan(xyz[..., 0])] = 0.0

    return xyz, mask, np.array(idx_s), np.array(chain_id)

def parse_pdb_lines_antibody(lines, item, antibody=True):

    """Same function as parse_pdb but for antibody -> add chain_id"""
    if antibody == True:
        chains = []
        for i in item.split("_")[1:]:
            for j in i:
                chains.append(j)
    else:
        chains = ['A', 'B']

    remove_set = {"#"}
    chains = [i for i in chains if i not in remove_set]
    chain_id = [chains.index(l[21]) for l in lines if l[:4] == "ATOM" and l[12:16].strip() == "CA"]
    idxs = np.array([int(l[22:26]) for l in lines if l[:4] == "ATOM" and l[12:16].strip() == "CA"])
    xyz = defaultdict(list)
    idx_s = defaultdict(list)
    mask = defaultdict(list)

    for i in sorted(list(set(chain_id))):
        idx_sel  = torch.squeeze(torch.nonzero(torch.tensor(chain_id) == i))
        xyz[i] = np.full((len(idx_sel), 14, 3), np.nan, dtype=np.float32)
        idx_s[i] = idxs[idx_sel]

    for l in lines:
        if l[:4] == 'ATOM':
            chain_id = chains.index(l[21])
            idx = np.where(idx_s[chain_id] == int(l[22:26]))
            atom = l[12:16]
            aa = l[17:20]
            for i_atm, tgtatm in enumerate(aa2long[aa2num[aa]]):
                if tgtatm == atom and i_atm < 14:
                    xyz[chain_id][idx, i_atm, :] = [float(l[30:38]), float(l[38:46]), float(l[46:54])]
                    break

    for k, v in xyz.items():
        mask[k] = torch.tensor(np.logical_not(np.isnan(v[..., 0])))
        v[np.isnan(v[..., 0])] = 0.0

    return xyz, mask, idx_s


def parse_pdb_lines_w_seq(lines):

    """Read and extract xyz coords of N, Ca, C atoms from a PDB file

    Args:
        lines (list): list of lines of PDB file

    Returns:
        xyz:  xyz coordinate of pdb file    [L, 14, 3] (14: 4BB + up to 10 SC atoms)
        mask: mask for atom existence       [L, 14]
        np.array(idx_s): residue number     [L]
        np.array(seq) : sequence            [L]
    """

    res = [
        (l[22:26], l[17:20])
        for l in lines
        if l[:4] == "ATOM" and l[12:16].strip() == "CA"
    ]
    idx_s = [int(r[0]) for r in res]
    seq = [aa2num[r[1]] if r[1] in aa2num.keys() else 20 for r in res]

    # 4 BB + up to 10 SC atoms
    xyz = np.full((len(idx_s), 14, 3), np.nan, dtype=np.float32)
    for l in lines:
        if l[:4] != "ATOM":
            continue
        resNo, atom, aa = int(l[22:26]), l[12:16], l[17:20]
        idx = idx_s.index(resNo)
        for i_atm, tgtatm in enumerate(aa2long[aa2num[aa]]):
            if tgtatm == atom and i_atm < 14:
                xyz[idx, i_atm, :] = [float(l[30:38]), float(l[38:46]), float(l[46:54])]
                break

    # save atom mask
    mask = np.logical_not(np.isnan(xyz[..., 0]))
    xyz[np.isnan(xyz[..., 0])] = 0.0

    return xyz, mask, np.array(idx_s), np.array(seq)


def parse_templates(params):

    """Parse templates from paramters

    Args:
        parameters (dictionary)
        params['FFDB']  : FFDB location
        params['hhr']   : hhr file location
        params['atab']  : atab file location

    Returns:
        xyz:  xyz coordinate of templates           [N_templ * L_align, 14, 3]
        mask: mask for atom existence               [N_templ * L_align, 14]
        qmap: aligned part of query, template no    [N_templ * L_align, 2]
        f0d: template properties                    [N_templ, 4]
             (Identities, Similarity, Sum_probs, Template_Neff)
        f1d: template properties per residue        [N_templ * L_align, 3]
             (Score, SS, prob)
        ids: template pdb id                        [N_templ]
        seq: template sequence                      [N_templ * L_align]
    """

    # init FFindexDB of templates
    ### and extract template IDs
    ### present in the DB
    #print('parse_templates', params['atab'])
    
    #start_time = time.time()

    FFindexDB = namedtuple("FFindexDB", "index, data")
    ffdb = FFindexDB(
        read_index(params["FFDB"] + "_pdb.ffindex"),
        read_data(params["FFDB"] + "_pdb.ffdata"),
    )
    
    #ffindex_time = time.time()
    #print('ffindex_time', ffindex_time - start_time)

    # ffids = set([i.name for i in ffdb.index])

    # process tabulated hhsearch output to get
    # matched positions and positional scores
    
    hits = []
    for l in open(params["atab"], "r", encoding="utf-8").readlines():
        if l[0] == ">":
            key = l[1:].split()[0]
            hits.append([key, [], []])
        elif "score" in l or "dssp" in l:
            continue
        else:
            hi = l.split()[:5] + [0.0, 0.0, 0.0]
            hits[-1][1].append([int(hi[0]), int(hi[1])])
            hits[-1][2].append([float(hi[2]), float(hi[3]), float(hi[4])])

    #get_hits_time = time.time()
    #print('get_hits_time', get_hits_time - ffindex_time)

    # get per-hit statistics from an .hhr file
    # (!!! assume that .hhr and .atab have the same hits !!!)
    # [Probab, E-value, Score, Aligned_cols,
    # Identities, Similarity, Sum_probs, Template_Neff]

    lines = open(params["hhr"], "r", encoding="utf-8").readlines()
    pos = [i + 1 for i, l in enumerate(lines) if l[0] == ">"]
    for i, posi in enumerate(pos):
        hits[i].append(
            [float(s) for s in re.sub("[=%]", " ", lines[posi]).split()[1::2]]
        )
    #read_hhr_time = time.time()
    #print('read_hhr_time', read_hhr_time - get_hits_time)
    # parse templates from FFDB
    #print(len(hits))
    for hi in hits:
        # if hi[0] not in ffids:
        #    continue
        #ffdb_start_time = time.time()
        entry = get_entry_by_name(hi[0], ffdb.index)
        
        #ffdb_read_entry_time = time.time()
        #print('ffdb_read_entry_time', ffdb_read_entry_time - ffdb_start_time)
        
        if entry is None:
            continue
        data = read_entry_lines(entry, ffdb.data)

        #ffdb_read_data_time = time.time()
        #print('ffdb_read_data_time', ffdb_read_data_time - ffdb_read_entry_time)
        
        hi += list(parse_pdb_lines_w_seq(data))

    #read_ffdb_time = time.time()
    #print('read_ffdb_time', read_ffdb_time - read_hhr_time)

    # process hits
    counter = 0
    xyz, qmap, mask, f0d, f1d, ids, seq = [], [], [], [], [], [], []
    for data in hits:
        if len(data) < 7:
            continue

        qi, ti = np.array(data[1]).T
        _, sel1, sel2 = np.intersect1d(ti, data[6], return_indices=True)
        ncol = sel1.shape[0]
        #if ncol < 10:
        #    continue

        ids.append(data[0])
        f0d.append(data[3])
        f1d.append(np.array(data[2])[sel1])
        xyz.append(data[4][sel2])
        mask.append(data[5][sel2])
        seq.append(data[-1][sel2])
        qmap.append(np.stack([qi[sel1] - 1, [counter] * ncol], axis=-1))
        counter += 1

    ids = ids
    xyz = np.vstack(xyz).astype(np.float32)
    #print('xyz_tplt', list(xyz))
    mask = np.vstack(mask).astype(bool)
    #print('tplt_mask', list(mask))
    qmap = np.vstack(qmap).astype(np.compat.long)
    f0d = np.vstack(f0d).astype(np.float32)
    f1d = np.vstack(f1d).astype(np.float32)
    seq = np.hstack(seq).astype(np.compat.long)

    #get_final_result = time.time()
    #print('get_final_result', get_final_result - read_ffdb_time)
    return {
        "xyz": torch.from_numpy(xyz),
        "mask": torch.from_numpy(mask),
        "qmap": torch.from_numpy(qmap),
        "f0d": torch.from_numpy(f0d),
        "f1d": torch.from_numpy(f1d),
        "ids": ids,
        "seq": torch.from_numpy(seq),
    }
